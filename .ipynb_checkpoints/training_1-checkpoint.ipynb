{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "np.random.seed(11)\n",
    "\n",
    "num_neuro_1 = 10\n",
    "num_neuro_2 = 10\n",
    "num_neuro_3 = 5\n",
    "\n",
    "RES_DIR = './results/'\n",
    "DATA_DIR = './CCPP/'\n",
    "HOME_DIR = './'\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_wts(net, save_dir, before=False, is_pytorch=False):\n",
    "    if is_pytorch:\n",
    "        net_wts = copy.deepcopy(net.state_dict())\n",
    "        if before:\n",
    "            torch.save(net_wts, save_dir+'params_before')\n",
    "        else:\n",
    "            torch.save(net_wts, save_dir+'params')\n",
    "    else:\n",
    "        !!! #ЧТО_ТО ИЗ ЭТОГО ТРАНСПОНИРУЕТСЯ\n",
    "        w1 = pd.DataFrame((net.lin1.W).data.numpy())\n",
    "        b1 = pd.DataFrame((net.lin1.b).data.numpy())\n",
    "        w2 = pd.DataFrame((net.lin2.W).data.numpy())\n",
    "        b2 = pd.DataFrame((net.lin2.b).data.numpy())\n",
    "        w3 = pd.DataFrame((net.lin3.W).data.numpy())\n",
    "        b3 = pd.DataFrame((net.lin3.b).data.numpy())\n",
    "        w4 = pd.DataFrame((net.lin4.W).data.numpy())\n",
    "        b4 = pd.DataFrame((net.lin4.b).data.numpy())\n",
    "        if before:\n",
    "            w1.to_csv(save_dir+'w1_before.csv', index=False)\n",
    "            w2.to_csv(save_dir+'w2_before.csv', index=False)\n",
    "            w3.to_csv(save_dir+'w3_before.csv', index=False)\n",
    "            w4.to_csv(save_dir+'w4_before.csv', index=False)\n",
    "            b1.to_csv(save_dir+'b1_before.csv', index=False)\n",
    "            b2.to_csv(save_dir+'b2_before.csv', index=False)\n",
    "            b3.to_csv(save_dir+'b3_before.csv', index=False)\n",
    "            b4.to_csv(save_dir+'b4_before.csv', index=False)\n",
    "        else:\n",
    "            w1.to_csv(save_dir+'w1_.csv', index=False)\n",
    "            w2.to_csv(save_dir+'w2_.csv', index=False)\n",
    "            w3.to_csv(save_dir+'w3_.csv', index=False)\n",
    "            w4.to_csv(save_dir+'w4_.csv', index=False)\n",
    "            b1.to_csv(save_dir+'b1_.csv', index=False)\n",
    "            b2.to_csv(save_dir+'b2_.csv', index=False)\n",
    "            b3.to_csv(save_dir+'b3_.csv', index=False)\n",
    "            b4.to_csv(save_dir+'b4_.csv', index=False)\n",
    "            \n",
    "def load_wts(net, load_dir, before=False, is_pytorch=False):  \n",
    "    path = load_dir\n",
    "    if before:\n",
    "        if is_pytorch:\n",
    "            net.load_state_dict(torch.load(load_dir+'params_before'))\n",
    "        else:\n",
    "            net.lin1.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w1_before.csv', sep=',').values))\n",
    "            net.lin2.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w2_before.csv', sep=',').values))\n",
    "            net.lin1.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b1_before.csv', sep=',').values).squeeze())\n",
    "            net.lin2.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b2_before.csv', sep=',').values).squeeze())\n",
    "            net.lin3.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w3_before.csv', sep=',').values))\n",
    "            net.lin4.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w4_before.csv', sep=',').values))\n",
    "            net.lin3.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b3_before.csv', sep=',').values).squeeze())\n",
    "            net.lin4.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b4_before.csv', sep=',').values).squeeze())\n",
    "    else:\n",
    "        if is_pytorch:\n",
    "            net.load_state_dict(torch.load(load_dir+'params'))\n",
    "        else:\n",
    "            net.lin1.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w1_.csv', sep=',').values))\n",
    "            net.lin2.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w2_.csv', sep=',').values))\n",
    "            net.lin1.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b1_.csv', sep=',').values).squeeze())\n",
    "            net.lin2.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b2_.csv', sep=',').values).squeeze())\n",
    "            net.lin3.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w3_.csv', sep=',').values))\n",
    "            net.lin4.W = Parameter(torch.FloatTensor(pd.read_csv(path+'w4_.csv', sep=',').values))\n",
    "            net.lin3.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b3_.csv', sep=',').values).squeeze())\n",
    "            net.lin4.b = Parameter(torch.FloatTensor(pd.read_csv(path+'b4_.csv', sep=',').values).squeeze())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(HOME_DIR+'split_data/train_set.csv').values\n",
    "val_set = pd.read_csv(HOME_DIR+'split_data/val_set.csv').values\n",
    "test_set = pd.read_csv(HOME_DIR+'split_data/test_set.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = len(train_set)\n",
    "IN_SIZE = 4\n",
    "OUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "п. 4.2\n",
    "\n",
    "Заметки:\n",
    "    1)все данные сначала - массивы numpy\n",
    "    2)это случай мини-бат-обучения, когда size_mini_batch=всей выборке\n",
    "    3)необходимо подобрать АХ выходного слоя !!!!!!!!!!!!!!\n",
    "    4)список lr_list - добработать           !!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CCPPDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "#dataset = CCPPDataset(train_set)\n",
    "dataloader = DataLoader(CCPPDataset(train_set), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Свой класс \n",
    "class Linear_batch(nn.Module):\n",
    "    def __init__(self, in_size, out_size, sigma):\n",
    "        super(Linear_batch, self).__init__()\n",
    "        self.W = Parameter(sigma * torch.randn((out_size, in_size)))\n",
    "        self.b = Parameter(sigma * torch.randn(out_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return (self.b + self.W.dot(self.x))\n",
    "    \n",
    "    def backward(self, dz, lr=0.001, rgr = 0.01):\n",
    "        self.dW = np.outer(dz, self.x)\n",
    "        self.db = dz\n",
    "        \n",
    "        self.dx = dz.dot(self.W) \n",
    "        \n",
    "        self.W -= lr*(self.dW + rgr*self.W)\n",
    "        self.db -= lr*(self.b + rgr*self.b)\n",
    "        \n",
    "        return self.dx\n",
    "\n",
    "    \n",
    "class tanh(nn.Module):\n",
    "    def forward(self, x):\n",
    "        self.fx = (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
    "        return (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        return (1 - self.fx**2)*dz\n",
    "    \n",
    "    \n",
    "class relu(nn.Module):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return Variable(np.maximum(0, x.data))\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        dz[self.x < 0] = 0\n",
    "        return dz\n",
    "    \n",
    "\n",
    "class Softmax(nn.Module):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        exps = np.exp(x)\n",
    "        return exps / np.sum(exps)\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        sm = self.forward(self.x)\n",
    "        self.lp = (np.eye(sm.shape[0], sm.shape[0]) - sm).T\n",
    "        self.lp2 = sm * self.lp\n",
    "        return np.dot(dz, self.lp2)    \n",
    "    \n",
    "    \n",
    "class Quadratic_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Quadratic_loss, self).__init__()\n",
    "        self.er = 0\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.er = y_pred - y_true\n",
    "        self.n = len(y_true)\n",
    "        return self.er**2 / self.n\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        return 2/self.n * self.er\n",
    "    \n",
    "    \n",
    "class MainNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MainNet, self).__init__()\n",
    "        self.lin1 = Linear_batch(IN_SIZE, num_neuro_1, 2/102)\n",
    "        self.ah1 = tanh()\n",
    "        self.lin2 = Linear_batch(num_neuro_1, num_neuro_2, 2/102)\n",
    "        self.ah2 = tanh()\n",
    "        self.lin3 = Linear_batch(num_neuro_2, num_neuro_3, 2/102)\n",
    "        self.ah3 = tanh()\n",
    "        self.lin4 = Linear_batch(num_neuro_3, OUT_SIZE, 2/102)\n",
    "        self.ah4 = tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.ah1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.ah2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.ah3(x)\n",
    "        x = self.lin4(x)\n",
    "        x = self.ah4(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, z):\n",
    "        z = self.ah4.backward(z)\n",
    "        z = self.lin4.backward(z)\n",
    "        z = self.ah3.backward(z)\n",
    "        z = self.lin3.backward(z)\n",
    "        z = self.ah2.backward(z)\n",
    "        z = self.lin2.backward(z)\n",
    "        z = self.ah1.backward(z)\n",
    "        z = self.lin1.backward(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainNet(\n",
      "  (lin1): Linear_batch(\n",
      "  )\n",
      "  (ah1): tanh(\n",
      "  )\n",
      "  (lin2): Linear_batch(\n",
      "  )\n",
      "  (ah2): tanh(\n",
      "  )\n",
      "  (lin3): Linear_batch(\n",
      "  )\n",
      "  (ah3): tanh(\n",
      "  )\n",
      "  (lin4): Linear_batch(\n",
      "  )\n",
      "  (ah4): tanh(\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lin1.W', \n",
       "              1.00000e-02 *\n",
       "                0.6342 -1.5806 -0.9526 -3.3209\n",
       "                2.0745 -0.5966  1.2304  0.0677\n",
       "                1.0485  1.0904  0.7758 -0.4275\n",
       "               -2.5902  1.7904 -1.8824  2.0768\n",
       "                4.0467  1.7170  2.9493  1.2990\n",
       "               -2.4260 -0.7553 -4.1591  0.0238\n",
       "               -1.3733 -3.1897 -0.7195  2.6180\n",
       "               -1.5315  0.9091 -1.0397 -0.3579\n",
       "                1.6079 -0.1178  0.4550 -1.8520\n",
       "               -1.2474  2.5717  1.5685 -0.6351\n",
       "              [torch.FloatTensor of size 10x4]), ('lin1.b', \n",
       "              1.00000e-02 *\n",
       "               -0.9126\n",
       "               -1.5187\n",
       "                0.4733\n",
       "               -2.2388\n",
       "                1.7904\n",
       "                0.3068\n",
       "                2.4439\n",
       "               -2.1016\n",
       "               -2.7033\n",
       "                3.7243\n",
       "              [torch.FloatTensor of size 10]), ('lin2.W', \n",
       "              1.00000e-02 *\n",
       "                1.0834 -1.2397 -3.8349  1.8899 -1.3222  2.7101  0.6538 -0.0951  3.8076 -1.8808\n",
       "                0.7984 -1.7125 -1.0870  3.2578  1.1838 -3.5283 -0.9360 -0.7804 -2.0954  0.5514\n",
       "                0.4179  0.7116 -0.4831  2.2996  3.7730  0.6431  1.0772  0.8278  5.8412  0.8247\n",
       "                1.6145  0.1126 -1.4256  2.0761  4.6039 -1.7567 -1.1935  0.3874 -1.8512  0.5944\n",
       "               -0.7944 -1.4705 -2.4397  0.3731 -3.4709 -0.8608  1.2619  1.4390 -0.4422 -2.8615\n",
       "                0.1991 -1.7835 -2.5305  0.3778 -1.7997 -2.3800  0.9460  0.4446 -1.9868 -1.0104\n",
       "               -1.5060 -1.9396 -1.9251 -0.6310  3.5347 -2.7862 -4.4306  1.3710 -1.4821  1.4552\n",
       "               -0.4920 -1.2565 -0.2346  0.2344 -0.5444  1.6079 -0.8636 -0.3691 -0.0812  2.1792\n",
       "                1.2898  3.8918 -0.1783 -0.2643  0.8559  1.4029  0.4690  2.1013 -2.2339  4.0531\n",
       "                3.3893 -2.8009  2.3890  3.6778  1.4081  1.8672  2.3056  0.6484  1.4743 -1.7689\n",
       "              [torch.FloatTensor of size 10x10]), ('lin2.b', \n",
       "              1.00000e-02 *\n",
       "                2.1120\n",
       "                0.9889\n",
       "                0.7456\n",
       "                1.7789\n",
       "                1.2984\n",
       "                0.3175\n",
       "                2.7148\n",
       "               -1.1208\n",
       "                0.8843\n",
       "               -2.1318\n",
       "              [torch.FloatTensor of size 10]), ('lin3.W', \n",
       "              1.00000e-02 *\n",
       "                0.1130  2.2191  0.4767  3.0530  1.1724 -3.7353  1.3122  1.7419 -1.7018  2.0573\n",
       "               -0.7985  1.4477  0.0352 -0.5854  1.7606 -3.3262 -0.0825  1.5065 -0.5234  1.3101\n",
       "                0.8214  2.6273  2.7914 -0.3167 -1.7650 -1.6603 -1.3421  3.0549 -0.0213 -0.0756\n",
       "                2.1012  0.0178  2.2079  1.2942 -0.1783 -0.5060 -1.4781  2.0519 -1.5057 -2.1444\n",
       "               -1.9081 -2.0862  0.8555 -2.1224  0.8618  0.5651  4.9672 -0.9188  1.4346 -1.4794\n",
       "              [torch.FloatTensor of size 5x10]), ('lin3.b', \n",
       "              1.00000e-02 *\n",
       "               -0.4258\n",
       "               -3.7779\n",
       "               -1.5358\n",
       "                1.3008\n",
       "                4.5936\n",
       "              [torch.FloatTensor of size 5]), ('lin4.W', \n",
       "              1.00000e-02 *\n",
       "               -0.9375  1.2131 -0.9665 -3.4351 -1.4148\n",
       "              [torch.FloatTensor of size 1x5]), ('lin4.b', \n",
       "              1.00000e-02 *\n",
       "                4.1616\n",
       "              [torch.FloatTensor of size 1])])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MainNet()\n",
    "print(net)\n",
    "\n",
    "# чтобы запуск был из одной точки\n",
    "first = False\n",
    "if first:\n",
    "    save_wts(net, HOME_DIR+'split_data/', before=True, is_pytorch=False)    \n",
    "else:\n",
    "    net = load_wts(net, HOME_DIR+'split_data/', before=True, is_pytorch=False)\n",
    "    \n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "err_epoh = []\n",
    "valid_err_epoh = []\n",
    "test_err_epoh = []\n",
    "\n",
    "num_epoch = 100000\n",
    "lr_list = [1e1, 0.5e1, 1e-1, 0.5e-1, 1e-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected argument self to have 1 dimension(s), but has 2 at c:\\anaconda2\\conda-bld\\pytorch_1519496000060\\work\\torch\\csrc\\generic\\TensorMethods.cpp:25700",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-73120683a6c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mvalid_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mIN_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected argument self to have 1 dimension(s), but has 2 at c:\\anaconda2\\conda-bld\\pytorch_1519496000060\\work\\torch\\csrc\\generic\\TensorMethods.cpp:25700"
     ]
    }
   ],
   "source": [
    "lr = lr_list[0]\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    err_acc = 0\n",
    "    valid_err_acc = 0\n",
    "    test_err_acc = 0\n",
    "\n",
    "    #lr = (lr0 + epoch)**(-1/3)\n",
    "    \n",
    "    if (epoch%1000 == 1):\n",
    "        plt.grid(True)\n",
    "        plt.plot(err_epoh, color='r')\n",
    "        plt.plot(valid_err_epoh, color='b')\n",
    "        plt.plot(test_err_epoh, color='g')\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        \n",
    "        print(epoch)\n",
    "        print(\"train: \", err_epoh[epoch-1])\n",
    "        print(\"valid: \", valid_err_epoh[epoch-1])\n",
    "        print(\"test: \", test_err_epoh[epoch-1])\n",
    "\n",
    "    \n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        #просчет производных\n",
    "        loss = Quadratic_loss()\n",
    "        \n",
    "        inputs, labels = data[:,0:IN_SIZE], data[:,IN_SIZE]\n",
    "        inputs = Variable((inputs).float()).unsqueeze(1)\n",
    "        labels = Variable((labels).float()).unsqueeze(1)\n",
    "        \n",
    "        valid_inputs = Variable(torch.from_numpy(val_set[:, 0:IN_SIZE]).float()).unsqueeze(1)\n",
    "        valid_labels = Variable(torch.from_numpy(val_set[:, IN_SIZE]).float()).unsqueeze(1)\n",
    "        test_inputs = Variable(torch.from_numpy(test_set[:, 0:IN_SIZE]).float()).unsqueeze(1)\n",
    "        test_labels = Variable(torch.from_numpy(test_set[:, IN_SIZE]).float()).unsqueeze(1)\n",
    "        \n",
    "        predict_valid = net.forward(valid_inputs)\n",
    "        \n",
    "        valid_err_acc = loss.forward(predict_valid, valid_labels)\n",
    "        predict_test = net.forward(test_inputs)\n",
    "        test_err_acc = loss.forward(predict_test, test_labels)\n",
    "        \n",
    "        predict = net.forward(inputs) \n",
    "        err_acc = loss.forward(predict, labels)\n",
    "        dz = loss.backward(1)\n",
    "        net.backward(dz)\n",
    "        \n",
    "        #обновление параметров\n",
    "        net.lin1.W.data = net.lin1.W.data - lr * net.lin1.dW.t().data\n",
    "        net.lin1.b.data = net.lin1.b.data - lr * net.lin1.db.data\n",
    "        net.lin2.W.data = net.lin2.W.data - lr * net.lin2.dW.t().data\n",
    "        net.lin2.b.data = net.lin2.b.data - lr * net.lin2.db.data\n",
    "        net.lin3.W.data = net.lin3.W.data - lr * net.lin3.dW.t().data\n",
    "        net.lin3.b.data = net.lin3.b.data - lr * net.lin3.db.data\n",
    "        net.lin4.W.data = net.lin4.W.data - lr * net.lin4.dW.t().data\n",
    "        net.lin4.b.data = net.lin4.b.data - lr * net.lin4.db.data\n",
    "        \n",
    "    err_iter = torch.sum(err_acc).data.numpy()\n",
    "    valid_err_iter = torch.sum(valid_err_acc).data.numpy()\n",
    "    test_err_iter = torch.sum(test_err_acc).data.numpy()\n",
    "    \n",
    "    valid_err_epoh.append(valid_err_iter)\n",
    "    test_err_epoh.append(test_err_iter)\n",
    "    err_epoh.append(err_iter)   \n",
    "\n",
    "plt.savefig(HOME_DIR+'GD/'+str(lr)+'train_valid_test.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сохранить веса сети\n",
    "save_wts(net, HOME_DIR+'GD/', before=False, is_pytorch=False)\n",
    "\n",
    "# средние ошибки\n",
    "print(\"train:\")\n",
    "print(np.mean(err_epoh))\n",
    "\n",
    "print(\"valid:\")\n",
    "print(np.mean(valid_err_epoh))\n",
    "\n",
    "print(\"test:\")\n",
    "print(np.mean(test_err_epoh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
